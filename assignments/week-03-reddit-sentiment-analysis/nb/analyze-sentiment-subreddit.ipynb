{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=”false” ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Reddit Data using Reddit API</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( 🤗 the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the session, you will "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- know how to work with APIs\n",
    "- feel more comfortable navigating thru documentation, even inspecting the source code\n",
    "- understand what a `pipeline` object is in HuggingFace\n",
    "- perform sentiment analysis using `pipeline`\n",
    "- run a python script in command line and get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At the end of each task, commit* the work into the repository you created before the assignment\n",
    "- After completing all three tasks, make sure to push the notebook containing all code blocks and output cells to your repository you created before the assignment\n",
    "- Submit the link to the notebook in Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\***NEVER** commit a notebook displaying errors unless it is instructed otherwise. However, commit often; recall git ABC = **A**lways **B**e **C**ommitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task I: Instantiate a Reddit API Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first task is to instantiate a Reddit API object using [PRAW](https://praw.readthedocs.io/en/stable/), through which you will retrieve data. PRAW is a wrapper for [Reddit API](https://www.reddit.com/dev/api) that makes interacting with the Reddit API easier unless you are already an expert of [`requests`](https://docs.python-requests.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Please ensure you've ran all the cells in the `imports.ipynb`, located [here](https://github.com/FourthBrain/MLE-8/blob/main/assignments/week-3-analyze-sentiment-subreddit/imports.ipynb), to make sure you have all the required packages for today's assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2. Create a new app on Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new app on Reddit and save secret tokens; refer to [post in medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Create a Reddit account if you don't have one, log into your account.\n",
    "- To access the API, we need create an app. Slight updates, on the website, you need to navigate to `preference` > `app`, or click [this link](https://www.reddit.com/prefs/apps) and scroll all the way down. \n",
    "- Click to create a new app, fill in the **name**, choose `script`, fill in  **description** and **redirect uri** ( The redirect URI is where the user is sent after they've granted OAuth access to your application (more info [here](https://github.com/reddit-archive/reddit/wiki/OAuth2)) For our purpose, you can enter some random url, e.g., www.google.com; as shown below.\n",
    "\n",
    "\n",
    "    <img src=\"https://miro.medium.com/max/700/1*lRBvxpIe8J2nZYJ6ucMgHA.png\" width=\"500\"/>\n",
    "- Jot down `client_id` (left upper corner) and `client_secret` \n",
    "\n",
    "    NOTE: CLIENT_ID refers to 'personal use script\" and CLIENT_SECRET to secret.\n",
    "    \n",
    "    <div>\n",
    "    <img src=\"https://miro.medium.com/max/700/1*7cGAKth1PMrEf2sHcQWPoA.png\" width=\"300\"/>\n",
    "    </div>\n",
    "\n",
    "- Create `secrets_reddit.py` in the same directory with this notebook, fill in `client_id` and `secret_id` obtained from the last step. We will need to import those constants in the next step.\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = \"client_id\"\n",
    "    REDDIT_API_CLIENT_SECRET = \"secret_id\"\n",
    "    REDDIT_API_USER_AGENT = \"any string except bot; ex. My User Agent\"\n",
    "    ```\n",
    "- Add `secrets_reddit.py` to your `.gitignore` file if not already done. NEVER push credentials to a repo, private or public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Instantiate a `Reddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you are ready to create a read-only `Reddit` instance. Refer to [documentation](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import secrets_reddit\n",
    "\n",
    "# Create a Reddit object which allows us to interact with the Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id = secrets_reddit.REDDIT_API_CLIENT_ID,\n",
    "    client_secret = secrets_reddit.REDDIT_API_CLIENT_SECRET,\n",
    "    user_agent = secrets_reddit.REDDIT_API_USER_AGENT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<praw.reddit.Reddit object at 0x109bd3550>\n"
     ]
    }
   ],
   "source": [
    "print(reddit) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "```<praw.reddit.Reddit object at 0x10f8a0ac0>```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Instantiate a `subreddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly, create a `subreddit` object for your favorite subreddit and inspect the object. The expected output you will see ar from `r/machinelearning` unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('todayilearned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the display name of the subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todayilearned\n"
     ]
    }
   ],
   "source": [
    "# display the subreddit name\n",
    "print(subreddit.display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    todayilearned\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How about its title, is it different from the display name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today I Learned (TIL)\n"
     ]
    }
   ],
   "source": [
    "# display the subreddit title\n",
    "print(subreddit.title) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    Today I Learned\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print out the description of the subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[](http://www.reddit.com/r/aww/#newlink)\n",
      "[New to reddit? Click here!](/wiki/reddit_101)\n",
      "\n",
      "\n",
      "\n",
      "* You learn something new every day; what did *you* learn today?\n",
      " \n",
      "* Submit interesting and **specific facts** that you just found out (not broad information you looked up, TodayILearned is not [/r/wikipedia](/r/wikipedia)).\n",
      " \n",
      "#Posting rules#\n",
      " \n",
      "1. **Submissions must be verifiable**. *Please link directly to a reliable source that supports every claim in your post title.* **Images alone do not count as valid references.** Videos are fine so long as they come from reputable sources (e.g. BBC, Discovery, etc).\n",
      "1. **No personal opinions, anecdotes or subjective statements** (e.g \"TIL xyz is a great movie\").\n",
      "\n",
      "1. **No recent sources.** Any sources (blog, article, press release, video, etc.) with a publication date more recent than two months are not allowed.\n",
      " \n",
      "1. No politics, soapboxing, or agenda based submissions. This includes (but is not limited to) submissions related to: \n",
      "   1. Recent political issues and politicians\n",
      "   1. Social and economic issues (including race/religion/gender)\n",
      "   1. Environmental issues\n",
      "   1. Police misconduct\n",
      " \n",
      "1. **No misleading claims**. Posts that omit essential information, or present unrelated facts in a way that suggest a connection will be removed.\n",
      " \n",
      "1. *Rephrase your post title if the following are not met:*\n",
      "   1. Titles **must** begin with \"TIL ...\"\n",
      "   1. Make them **descriptive, concise and specific** (e.g. not \"TIL something interesting about bacon\").\n",
      "   1. Titles must be able to **stand on their own** without requiring readers to click on a link. Starting your title with a why/what/who/where/how modifier should be unnecessary.\n",
      "   1. *\"TIL about ...\" and other broad posts don't belong on TIL. Try /r/Wikipedia, etc. instead, or be more specific (and avoid the word \"about\").*\n",
      "   1. *\"TIL how to ...\" posts belong on* **/r/HowTo.**\n",
      "   1. *\"TIL the definition of a word...\" Word definitions/translations/origins are not appropriate here*\n",
      "\n",
      "1. No submissions related to the usage, existence or features of specific software/websites (e.g. \"TIL you can click on widgets in WidgetMaker 1.22\").\n",
      "\n",
      "1.  **All NSFW links must be tagged** *(including comments).*\n",
      "####  *Please see the [wiki](http://www.reddit.com/r/todayilearned/wiki/index) for more detailed explanations of the rules, as well as additional rules that may not be listed here*\n",
      "\n",
      "\n",
      "\n",
      "([Why we need rules](http://www.reddit.com/wiki/faq#wiki_why_does_reddit_need_moderation.3F_can.27t_you_just_let_the_voters_decide.3F))\n",
      " \n",
      "#Additional info#\n",
      " \n",
      "* If your post does not appear in the [new queue](http://www.reddit.com/r/todayilearned/new/) and you think it meets the above rules, please **[contact the moderators](http://www.reddit.com/message/compose?to=%23todayilearned)** (include a link to your *reddit.com* post, not your story).\n",
      " \n",
      "* Please report spam, inaccurate or otherwise inappropriate posts by [messaging the moderators](http://www.reddit.com/message/compose?to=%23todayilearned), as this helps us remove them more promptly!\n",
      "\n",
      "* More information available on the [TIL FAQ](http://www.reddit.com/r/todayilearned/wiki/faq) and [wiki.](http://www.reddit.com/r/todayilearned/wiki) \n",
      "\n",
      "#Frequent TILs Repost List#\n",
      "As of February 2022\n",
      "\n",
      "* This [list](https://www.reddit.com/r/todayilearned/wiki/index#wiki_frequent_tils_repost_list) was compiled from /r/todayilearned community [suggestions](https://www.reddit.com/r/todayilearned/comments/4dnulc/request_for_identification_of_frequent_tils/?sort=top) by its members. If your TIL is found on this list, it will be removed. The titles have been abridged for the sake of brevity, however the context remains the same. This list is subject to change. The purpose is to keep content fresh on /r/todayilearned as requested by its members. If you are interested in reading about the TILs on this list use the [search box](https://www.reddit.com/r/todayilearned/search?q=&restrict_sr=on&sort=relevance&t=all) feature and enter the keywords to pull up past TILs. \n",
      "\n",
      "\n",
      "----\n",
      " \n",
      "#Etiquette#\n",
      " \n",
      "We ask that you *please* do the following:\n",
      "\n",
      "1. *avoid mobile versions of websites (e.g. [m.wikipedia.org](http://m.wikipedia.org))*\n",
      " \n",
      "1. *link to the appropriate heading when referencing an article (particularly on Wikipedia)*\n",
      " \n",
      "1. *link to the appropriate start time when referencing videos (e.g. [on YouTube](http://youtubetime.com/))*\n",
      " \n",
      "1. *add [PDF] or [NSFW] tags to your posts, as necessary.*\n",
      "\n",
      "1. *Please avoid reposting TILs that have already made the front page in the past*\n",
      "\n",
      "\n",
      "[](#space)\n",
      "\n",
      "Please also read the site-wide [Reddiquette](http://www.reddit.com/help/reddiquette).\n",
      "\n",
      "---\n",
      "\n",
      "* *You are loved.*\n",
      "\n",
      "[](#/RES_SR_Config/NightModeCompatible)\n"
     ]
    }
   ],
   "source": [
    "# display the subreddit description\n",
    "print(subreddit.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "    **[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
    "    --------\n",
    "    +[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
    "    --------\n",
    "    +[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
    "    --------\n",
    "    +[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
    "    --------\n",
    "    +[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task II: Parse comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1. Top Posts of All Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Find titles of top 10 posts of **all time** from your favorite subreddit. Refer to [Obtain Submission Instances from a Subreddit Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)) if necessary. Verify if the titles match what you read on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0msubreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtime_filter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mgenerator_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Return a :class:`.ListingGenerator` for top items.\n",
      "\n",
      ":param time_filter: Can be one of: ``\"all\"``, ``\"day\"``, ``\"hour\"``,\n",
      "    ``\"month\"``, ``\"week\"``, or ``\"year\"`` (default: ``\"all\"``).\n",
      "\n",
      ":raises: :py:class:`ValueError` if ``time_filter`` is invalid.\n",
      "\n",
      "Additional keyword arguments are passed in the initialization of\n",
      ":class:`.ListingGenerator`.\n",
      "\n",
      "This method can be used like:\n",
      "\n",
      ".. code-block:: python\n",
      "\n",
      "    reddit.domain(\"imgur.com\").top(time_filter=\"week\")\n",
      "    reddit.multireddit(redditor=\"samuraisam\", name=\"programming\").top(time_filter=\"day\")\n",
      "    reddit.redditor(\"spez\").top(time_filter=\"month\")\n",
      "    reddit.redditor(\"spez\").comments.top(time_filter=\"year\")\n",
      "    reddit.redditor(\"spez\").submissions.top(time_filter=\"all\")\n",
      "    reddit.subreddit(\"all\").top(time_filter=\"hour\")\n",
      "\u001b[0;31mFile:\u001b[0m      /opt/homebrew/Caskroom/miniforge/base/envs/sa/lib/python3.8/site-packages/praw/models/listing/mixins/base.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "# try run this line, what do you see? press q once you are done\n",
    "?subreddit.top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIL During an interview with Stephen Hawking, the camera operator yanked a cable causing an alarm and Hawking to slump forward. Worried they had killed him, everyone rushed over to find Hawking giggling at his own joke. The alarm was from an office computer losing power.\n",
      "TIL Genghis Khan would marry off a daughter to the king of an allied nation. Then he would assign his new son in law to military duty in the Mongol wars, while his daughter took over the rule. Most sons in law died in combat, giving his daughters complete control of these nations\n",
      "TIL the FBI has struggled to hire hackers because of the FBI hiring rule that the applicant must not have used marijuana during the last 3 years.\n",
      "TIL After Col. Shaw died in battle, Confederates buried him in a mass grave as an insult for leading black soldiers. Union troops tried to recover his body, but his father sent a letter saying \"We would not have his body removed from where it lies surrounded by his brave and devoted soldiers.\"\n",
      "TIL a fan drove three hours to deliver rapper, Boozie Badazz, a much needed dosage of insulin. She refused to accept payment and instead asked for just a photo. On her way home she stopped at a store, bought a scratch off ticket, and won $10,000.\n",
      "TIL that in 1916 there was a proposed Amendment to the US Constitution that would put all acts of war to a national vote, and anyone voting yes would have to register as a volunteer for service in the United States Army.\n",
      "TIL that the Animal Planet reality series ‘River Monsters’ ended because star Jeremy Wade was able to catch essentially every exceptionally large freshwater fish species on earth, leaving no remaining content for the show\n",
      "TIL actor Robert Pattinson dealt with an obsessed fan who had been camping outside his apartment by taking her out on a dinner date. \"I just complained about everything in my life and she never came back.\"\n",
      "TIL that millennial dads are spending 3 times as much times with their kids than their fathers spent with them. Back in 1982, 43% of fathers admitted they'd never changed a diaper. Today, that number is down to about 3%.\n",
      "TIL The cast of FRIENDS each made $1M per episode in the final two seasons and now make $20M per year per cast member for reruns. The show still generates $1B/year for Warner Bros. All thanks to David Schwimmer encouraging the cast to negotiate as a team.\n"
     ]
    }
   ],
   "source": [
    "# the previous cell returns documentation for using the .top method.\n",
    "# the output matches the top tdil posts here: https://www.reddit.com/r/todayilearned/top/?t=all\n",
    "tdil_alltime_posts = subreddit.top(time_filter='all', limit=10)\n",
    "for post in tdil_alltime_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details> <summary>Expected output:</summary>\n",
    "\n",
    "    [Project] From books to presentations in 10s with AR + ML\n",
    "    [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
    "    [R] First Order Motion Model applied to animate paintings\n",
    "    [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
    "    [D] This AI reveals how much time politicians stare at their phone at work\n",
    "    [D] Types of Machine Learning Papers\n",
    "    [D] The machine learning community has a toxicity problem\n",
    "    [Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
    "    [P] Using oil portraits and First Order Model to bring the paintings back to life\n",
    "    [D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG)    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2. Top 10 Posts of This Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What are the titles of the top 10 posts of **this week** from your favorite subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIL no child has been harmed or killed by poisoned or dangerous Halloween candy.\n",
      "TIL cats were a common wedding gift among Vikings due to their association with the goddess of luck, Freyja. Men favored women who loved cats, believing that it increased the likelihood of a happy marriage.\n",
      "TIL about millionaire Wellington Burt, who died in 1919 and deliberately held back his enormous fortune. His will denied any inheritance until 21 years after the death of his last surviving grandchild. The money sat in a trust for 92 years, until 12 descendants finally shared $110 million in 2011.\n",
      "TIL about death flights. Captives would be loaded into a plane, stripped, and pushed out over the ocean. These account for 1500-2000 of the 20k-30k estimated to have been disappeared by the Argentine military between 1976 and 1983 in the Argentine Dirty War.\n",
      "TIL that in 1996 a 7-year-old Californian girl tried to fly an airplane across the US and crashed in a thunderstorm, killing her. This resulted in a law banning children from flying.\n",
      "TIL that the popular belief in the United States that Daylight Savings Time was enacted FOR the benefit of farmers is wrong; farmers were actually some of the strongest opponents of its implementation.\n",
      "TIL it’s called “20,000 leagues under the sea” because they travel 20,000 leagues while under water, not because they go 20,000 leagues deep.\n",
      "TIL that Alan Turing, the mathematician renowned for his contributions to computer science and codebreaking, converted his savings into silver during WW2 and buried it, fearing German invasion. However, he was unable to break his own code describing where it was hidden, and never recovered it.\n",
      "TIL Japan is considered a \"super-aged\" nation since more than 20% of the population is over 65\n",
      "TIL that potato plants are poisonous. The part that we eat is the only edible part of the whole plant. It's also a member of the nightshade family.\n"
     ]
    }
   ],
   "source": [
    "# output can be validated here: https://www.reddit.com/r/todayilearned/top/?t=week\n",
    "tdil_topweek_posts = subreddit.top(time_filter='week', limit=10)\n",
    "for post in tdil_topweek_posts:\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details><summary>Expected output:</summary>\n",
    "\n",
    "    [N] Ian Goodfellow, Apple’s director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said “I believe strongly that more flexibility would have been the best policy for my team.” He was likely the company’s most cited ML expert.\n",
    "    [R][P] Thin-Plate Spline Motion Model for Image Animation + Gradio Web Demo\n",
    "    [P] I’ve been trying to understand the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple’s version of MobileNet, and more directly on your phone's camera roll.\n",
    "    [R] Meta is releasing a 175B parameter language model\n",
    "    [N] Hugging Face raised $100M at $2B to double down on community, open-source & ethics\n",
    "    [P] T-SNE to view and order your Spotify tracks\n",
    "    [D] : HELP Finding a Book - A book written for Google Engineers about foundational Math to support ML\n",
    "    [R] Scaled up CLIP-like model (~2B) shows 86% Zero-shot on Imagenet\n",
    "    [D] Do you use NLTK or Spacy for text preprocessing?\n",
    "    [D] Democratizing Diffusion Models - LDMs: High-Resolution Image Synthesis with Latent Diffusion Models, a 5-minute paper summary by Casual GAN Papers\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "Check out what other attributes the `praw.models.Submission` class has in the [docs](https://praw.readthedocs.io/en/stable/code_overview/models/submission.html). \n",
    "\n",
    "1. After having a chance to look through the docs, is there any other information that you might want to extract? How might this additional data help you?\n",
    "\n",
    "Answer: If my goal were to better understand how popularity/rankings are quantified, then I would choose to look at attributes such as:\n",
    "1. Score\n",
    "2. Up-vote ratio\n",
    "3. Num_comments\n",
    "4. Comments\n",
    "\n",
    "These additional attributes would give me information about user engagement on these posts.\n",
    "\n",
    "Write a sample piece of code below extracting three additional pieces of information from the submission below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hbrimd</td>\n",
       "      <td>2020-06-19 01:35:04</td>\n",
       "      <td>TIL During an interview with Stephen Hawking, ...</td>\n",
       "      <td>163096</td>\n",
       "      <td>1829</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgl7ag</td>\n",
       "      <td>2021-02-10 03:47:28</td>\n",
       "      <td>TIL Genghis Khan would marry off a daughter to...</td>\n",
       "      <td>161994</td>\n",
       "      <td>3292</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gjmajm</td>\n",
       "      <td>2020-05-14 13:25:42</td>\n",
       "      <td>TIL the FBI has struggled to hire hackers beca...</td>\n",
       "      <td>156709</td>\n",
       "      <td>7824</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7pbzcb</td>\n",
       "      <td>2018-01-10 01:13:53</td>\n",
       "      <td>TIL After Col. Shaw died in battle, Confederat...</td>\n",
       "      <td>155469</td>\n",
       "      <td>4237</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i8pq5h</td>\n",
       "      <td>2020-08-13 00:24:53</td>\n",
       "      <td>TIL a fan drove three hours to deliver rapper,...</td>\n",
       "      <td>154782</td>\n",
       "      <td>3156</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8ih4tq</td>\n",
       "      <td>2018-05-10 18:34:18</td>\n",
       "      <td>TIL that in 1916 there was a proposed Amendmen...</td>\n",
       "      <td>153133</td>\n",
       "      <td>5247</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tlmlnw</td>\n",
       "      <td>2022-03-23 23:54:05</td>\n",
       "      <td>TIL that the Animal Planet reality series ‘Riv...</td>\n",
       "      <td>151908</td>\n",
       "      <td>3613</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eb15tp</td>\n",
       "      <td>2019-12-15 16:47:11</td>\n",
       "      <td>TIL actor Robert Pattinson dealt with an obses...</td>\n",
       "      <td>149162</td>\n",
       "      <td>2759</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ejwxed</td>\n",
       "      <td>2020-01-04 13:59:08</td>\n",
       "      <td>TIL that millennial dads are spending 3 times ...</td>\n",
       "      <td>147997</td>\n",
       "      <td>7010</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i7irad</td>\n",
       "      <td>2020-08-11 01:53:49</td>\n",
       "      <td>TIL The cast of FRIENDS each made $1M per epis...</td>\n",
       "      <td>147077</td>\n",
       "      <td>5499</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             created  \\\n",
       "0  hbrimd 2020-06-19 01:35:04   \n",
       "1  lgl7ag 2021-02-10 03:47:28   \n",
       "2  gjmajm 2020-05-14 13:25:42   \n",
       "3  7pbzcb 2018-01-10 01:13:53   \n",
       "4  i8pq5h 2020-08-13 00:24:53   \n",
       "5  8ih4tq 2018-05-10 18:34:18   \n",
       "6  tlmlnw 2022-03-23 23:54:05   \n",
       "7  eb15tp 2019-12-15 16:47:11   \n",
       "8  ejwxed 2020-01-04 13:59:08   \n",
       "9  i7irad 2020-08-11 01:53:49   \n",
       "\n",
       "                                               title   score  num_comments  \\\n",
       "0  TIL During an interview with Stephen Hawking, ...  163096          1829   \n",
       "1  TIL Genghis Khan would marry off a daughter to...  161994          3292   \n",
       "2  TIL the FBI has struggled to hire hackers beca...  156709          7824   \n",
       "3  TIL After Col. Shaw died in battle, Confederat...  155469          4237   \n",
       "4  TIL a fan drove three hours to deliver rapper,...  154782          3156   \n",
       "5  TIL that in 1916 there was a proposed Amendmen...  153133          5247   \n",
       "6  TIL that the Animal Planet reality series ‘Riv...  151908          3613   \n",
       "7  TIL actor Robert Pattinson dealt with an obses...  149162          2759   \n",
       "8  TIL that millennial dads are spending 3 times ...  147997          7010   \n",
       "9  TIL The cast of FRIENDS each made $1M per epis...  147077          5499   \n",
       "\n",
       "   upvote_ratio  \n",
       "0          0.97  \n",
       "1          0.95  \n",
       "2          0.96  \n",
       "3          0.93  \n",
       "4          0.93  \n",
       "5          0.93  \n",
       "6          0.95  \n",
       "7          0.96  \n",
       "8          0.95  \n",
       "9          0.94  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additional information\n",
    "import pandas as pd\n",
    "\n",
    "tdil_posts = []\n",
    "for post in subreddit.top(limit=10):\n",
    "    tdil_posts.append(\n",
    "    [   post.id,\n",
    "        post.created,\n",
    "        post.title, \n",
    "        post.score,\n",
    "        post.num_comments, \n",
    "        post.upvote_ratio\n",
    "    ]\n",
    "        )\n",
    "posts = pd.DataFrame(\n",
    "    tdil_posts,\n",
    "    columns=\n",
    "    [ \n",
    "        'id',\n",
    "        'created', \n",
    "        'title', \n",
    "        'score', \n",
    "        'num_comments', \n",
    "        'upvote_ratio'\n",
    "    ]   \n",
    ")\n",
    "\n",
    "# convert the created column to a datetime object\n",
    "posts[\"created\"] = pd.to_datetime(posts[\"created\"], unit=\"s\")\n",
    "\n",
    "posts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "2. Is there any information available that might be a concern when it comes to Ethical Data?\n",
    "\n",
    "Answer: While the subreddit I reviewed is relatively benign in regards to inflammatory content, it is still managed by a small group of content moderators who have the power to approve/disapprove of submitted content. The submissions are basically gated, so all comments should be scrutinized for various types of biases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3. Comment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add comments to the code block below to describe what each line of the code does (Refer to [Obtain Comment Instances Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html) when necessary). The code is adapted from [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
    "\n",
    "The purpose is \n",
    "1. to understand what the code is doing \n",
    "2. start to comment your code whenever it is not self-explantory if you have not (others will thank you, YOU will thank you later 😊) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 690 ms, sys: 56.1 ms, total: 746 ms\n",
      "Wall time: 45.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# Create a list object to hold top comments for each post\n",
    "top_comments = []\n",
    "\n",
    "# Outer loop iterates through each post and will only show the top 10 posts\n",
    "for submission in subreddit.top(limit=10):\n",
    "    # Innner loop iterates through each comment in the post. \n",
    "    for top_level_comment in submission.comments:\n",
    "        # Use the isinstance function to check whether the comment is a MoreComments object. If so, continue.\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # Add the comment to the list\n",
    "        top_comments.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 4. Inspect Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How many comments did you extract from the last step? Examine a few comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many comments were extracted?\n",
    "len(top_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">*Following Hawking's death in March 2018, BBC science correspondent Pallab Ghosh shared an anecdote of his first interview with the physics luminary at Cambridge University in 2004.*\n",
      "\n",
      ">*Seeking to adjust his lighting, the camera operator yanked a cable from a socket, at which point an alarm sounded and Hawking slumped forward as if unplugged from his life support. The anxious visitors rushed over to find Hawking very much alive and giddy at his joke – the alarm was simply over the office computer losing its power supply.*\n",
      "\n",
      "I can imagine for a moment, that camera man saw his life flash before his eyes.\n"
     ]
    }
   ],
   "source": [
    "print(top_comments[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TIL I cannot work at the FBI until May 14th 2023',\n",
       " 'Is it true that the cast of Fraiser were paid even more than that per episode?',\n",
       " 'Legend']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "[random.choice(top_comments) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> <summary>Some of the comments from `r/machinelearning` subreddit are:</summary>\n",
    "\n",
    "    ['Awesome visualisation',\n",
    "    'Similar to a stack or connected neurons.',\n",
    "    'Will this Turing pass the Turing Test?']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "3. After having a chance to review a few samples of 5 comments from the subreddit, what can you say about the data? \n",
    "\n",
    "HINT: Think about the \"cleanliness\" of the data, the content of the data, think about what you're trying to do - how does this data line up with your goal?\n",
    "\n",
    "Answer:\n",
    "The data contains different entities, such as names, people, and places, that would be interesting to extract to perform some type of topic modeling. For example, if I wanted to dive deeper into the world of Stephen Hawking, the comments would provide a window into some of the more poignant parts of his life. However, these comments are told by people who likely did not have direct contact with Hawking. The results of any topic modeling, or named entity recognition (NER), would need further review before drawing definitive conclusions. As previously mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5. Extract Top Level Comment from Subreddit `TSLA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Write your code to extract top level comments from the top 10 topics of a time period, e.g., year, from subreddit `TSLA` and store them in a list `top_comments_tsla`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a list object to hold top comments for each post, and then populate the list by iterating through each post\n",
    "top_comments_tsla = []\n",
    "for submission in reddit.subreddit('tsla').top(time_filter = 'year', limit=10):\n",
    "    for top_level_comment in submission.comments:\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        top_comments_tsla.append(top_level_comment.body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_comments_tsla) # Expected: 174 for r/machinelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[removed]',\n",
       " \"I don't see my split...\",\n",
       " 'Who believes that crazy rumor he is going to announce something on 12/9?']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[random.choice(top_comments_tsla) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Some of the comments from `r/TSLA` subreddit:</summary>\n",
    "\n",
    "    ['I bought puts',\n",
    "    '100%',\n",
    "    'Yes. And I’m bag holding 1200 calls for Friday and am close to throwing myself out the window']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "4. Now that you've had a chance to review another subreddits comments, do you see any differences in the kinds of comments either subreddit has - and how might this relate to bias?\n",
    "\n",
    "Answer: Absolutely. It is more apparent in the TSLA subreddit that there are stronger currents of bias. I believe this has to do with the purpose of the subreddit itself, which is to provide a forum for Tesla enthusiasts. This is different than the r/TIL subreddit, which isn't centered around a product. For example, in just a few comments in the TSLA subreddit I can see a temptation to use the information to draw immediate conclusions about the health of Tesla the company (confirmation bias). Selection and availability bias are also evident. If my goal were to analyze customer sentiment surrounding Tesla, then I wouldn't use just this dataset to analyze Tesla. I would search for other data sources to balance r/TSLA's inherent bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task III: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us analyze the sentiment of comments scraped from `r/TSLA` using a pre-trained HuggingFace model to make the inference. Take a [Quick tour](https://huggingface.co/docs/transformers/quicktour). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Import `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2. Create a Pipeline to Perform Task \"sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "#Create a pipeline object using the twitter-roberta-base sentiment model - trained on 58m tweets\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Get one comment from list `top_comments_tsla` from Task II - 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "comment = np.random.choice(top_comments_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 100 shares and also got a bunch of Put options.  Protective put.\n"
     ]
    }
   ],
   "source": [
    "print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example comment is: `'Bury Burry!!!!!'`. Print out what you get. For reproducibility, use the same comment in the next step; consider setting a seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Make Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sentiment = sentiment_model(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the type of the output `sentiment`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "Answer: The type of the output 'sentiment' is a numpy.string_ because I set the seed using the Numpy module\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment: Got 100 shares and also got a bunch of Put options.  Protective put.\n",
      "Predicted Label is POSITIVE and the score is 0.620\n"
     ]
    }
   ],
   "source": [
    "print(f'The comment: {comment}')\n",
    "print(f'Predicted Label is {sentiment[0][\"label\"]} and the score is {sentiment[0][\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example comment, the output is:\n",
    "\n",
    "    The comment: Bury Burry!!!!!\n",
    "    Predicted Label is NEGATIVE and the score is 0.989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🖥️❓ Model Question:\n",
    "\n",
    "1. What does the score represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task IV: Put All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull all the piece together, create a simple script that does \n",
    "\n",
    "- get the subreddit\n",
    "- get comments from the top posts for given subreddit\n",
    "- run sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you complete the code, running the following block writes the code into a new Python script and saves it as `top_tlsa_comment_sentiment.py` under the same directory with the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing top_tsla_comment_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_tsla_comment_sentiment.py\n",
    "\n",
    "import secrets_reddit\n",
    "import random\n",
    "import praw\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "from praw import Reddit\n",
    "from praw.models.reddit.subreddit import Subreddit\n",
    "from praw.models import MoreComments\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "def get_subreddit(display_name:str) -> Subreddit:\n",
    "    \"\"\"Get subreddit object from display name\n",
    "\n",
    "    Args:\n",
    "        display_name (str): [description]\n",
    "\n",
    "    Returns:\n",
    "        Subreddit: [description]\n",
    "    \"\"\"\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=secrets_reddit.REDDIT_API_CLIENT_ID,        \n",
    "        client_secret=secrets_reddit.REDDIT_API_CLIENT_SECRET,\n",
    "        user_agent=secrets_reddit.REDDIT_API_USER_AGENT\n",
    "        )\n",
    "    \n",
    "    subreddit = reddit.subreddit(display_name)\n",
    "    return subreddit\n",
    "\n",
    "def get_comments(subreddit:Subreddit, limit:int=3) -> List[str]:\n",
    "    \"\"\" Get comments from subreddit\n",
    "\n",
    "    Args:\n",
    "        subreddit (Subreddit): [description]\n",
    "        limit (int, optional): [description]. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of comments\n",
    "    \"\"\"\n",
    "    top_comments = []\n",
    "    for submission in subreddit.top(limit=limit):\n",
    "        for top_level_comment in submission.comments:\n",
    "            if isinstance(top_level_comment, MoreComments):\n",
    "                continue\n",
    "            top_comments.append(top_level_comment.body)\n",
    "    return top_comments\n",
    "\n",
    "def run_sentiment_analysis(comment:str) -> Dict:\n",
    "    \"\"\"Run sentiment analysis on comment using default distilbert model\n",
    "    \n",
    "    Args:\n",
    "        comment (str): [description]\n",
    "        \n",
    "    Returns:\n",
    "        str: Sentiment analysis result\n",
    "    \"\"\"\n",
    "    sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "    sentiment = sentiment_model(comment)\n",
    "    return sentiment[0]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    subreddit = get_subreddit('tsla')\n",
    "    comments = get_comments(subreddit)\n",
    "    comment = random.choice(comments)\n",
    "    sentiment = run_sentiment_analysis(comment)\n",
    "    \n",
    "    print(f'The comment: {comment}')\n",
    "    print(f'Predicted Label is {sentiment[\"label\"]} and the score is {sentiment[\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "The comment: BEEEEET-CO-NNNNNNNNNNEEEEEEEEEEEEEEEECT\n",
      "Predicted Label is NEGATIVE and the score is 0.995\n"
     ]
    }
   ],
   "source": [
    "!python top_tsla_comment_sentiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Expected output:</summary>\n",
    "\n",
    "    No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "    The comment: When is DOGE flying\n",
    "    Predicted Label is POSITIVE and the score is 0.689\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "5. Is the subreddit active? About how many posts or threads per day? How could you find this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: If by active we mean there are active users, then r/TSLA is active. You can quickly look at active_user_count when you use the built-in vars() function on the tsla subreddit. Basically, tsla_subreddit.active_user_count. It appears that getting posts (or threads) per day is a little more challening. I think the best way to do this would be to bring the comments into a dataframe and conduct some lightweight EDA to determine the mean/median of posts per day. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💽❓ Data Question:\n",
    "\n",
    "6. Does there seem to be a large distribution of posters or a smaller concentration of posters who are very active? What kind of impact might this have on the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There are a smaller concentraction of posters (12) who are very active. This presents a narrower viewpoint of the subject matter, which is organized around Tesla's stock. Without more diversity of content and opinion, then it's difficult to tell if the data has a hidden agenda. I would not rely on this data alone to help me determine the short and long-term health of Tesla's stock. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "626b912eea1ca9e60b08b4095c9bcba9465862c442d86ce610120fb29ae02e42"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
